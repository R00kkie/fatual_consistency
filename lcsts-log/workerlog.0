/data/lzp/anaconda3/envs/race/lib/python3.7/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")
-----------  Configuration Arguments -----------
batch_size: 64
beta1: 0.9
beta2: 0.98
dataset_name: lcsts_new
decode_strategy: beam_search
device: gpu
do_predict: True
do_train: True
epochs: 6
epsilon: 1e-06
learning_rate: 5e-05
length_penalty: 1.2
logging_steps: 100
max_dec_len: 20
max_grad_norm: 1.0
max_seq_len: 320
max_target_len: 30
max_title_len: 30
min_dec_len: 3
model_name_or_path: unimo-text-1.0
num_beams: 6
num_return_sequences: 1
output_path: ./predict.txt
predict_file: None
save_dir: ./lcsts-log/checkpoints
save_steps: 10000
seed: 1
temperature: 1.0
top_k: 0
top_p: 1.0
train_file: None
warmup_propotion: 0.02
weight_decay: 0.01
------------------------------------------------
[32m[2023-02-10 11:12:30,639] [    INFO][0m - Model config UNIMOConfig {
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 1,
  "eos_token_id": 3,
  "hidden_act": "relu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "mask_token_id": 3,
  "max_position_embeddings": 513,
  "model_type": "unimo",
  "normalize_before": false,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "paddlenlp_version": null,
  "type_vocab_size": 4,
  "unk_token_id": 17963,
  "vocab_size": 18000
}
[0m
[32m[2023-02-10 11:12:30,640] [    INFO][0m - Configuration saved in /data/lzp/.paddlenlp/models/unimo-text-1.0/config.json[0m
[32m[2023-02-10 11:12:30,640] [    INFO][0m - Downloading unimo-text-1.0.pdparams from https://bj.bcebos.com/paddlenlp/models/transformers/unimo/unimo-text-1.0.pdparams[0m
  0%|          | 0.00/434M [00:00<?, ?B/s]  1%|          | 2.24M/434M [00:00<00:19, 23.5MB/s]  3%|â–Ž         | 12.4M/434M [00:00<00:06, 72.1MB/s]  5%|â–Œ         | 22.6M/434M [00:00<00:05, 81.3MB/s]  8%|â–Š         | 33.5M/434M [00:00<00:04, 93.6MB/s] 10%|â–ˆ         | 45.0M/434M [00:00<00:03, 103MB/s]  13%|â–ˆâ–Ž        | 55.4M/434M [00:00<00:03, 105MB/s] 15%|â–ˆâ–Œ        | 65.4M/434M [00:00<00:04, 95.1MB/s] 18%|â–ˆâ–Š        | 77.1M/434M [00:00<00:03, 103MB/s]  20%|â–ˆâ–ˆ        | 87.1M/434M [00:00<00:03, 101MB/s] 22%|â–ˆâ–ˆâ–       | 96.9M/434M [00:01<00:03, 92.3MB/s] 25%|â–ˆâ–ˆâ–Œ       | 109M/434M [00:01<00:03, 101MB/s]   28%|â–ˆâ–ˆâ–Š       | 120M/434M [00:01<00:03, 107MB/s] 30%|â–ˆâ–ˆâ–ˆ       | 131M/434M [00:01<00:02, 109MB/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 142M/434M [00:01<00:02, 111MB/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 153M/434M [00:01<00:02, 111MB/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 164M/434M [00:01<00:02, 112MB/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 175M/434M [00:01<00:02, 113MB/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 186M/434M [00:01<00:02, 114MB/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 197M/434M [00:02<00:02, 104MB/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 207M/434M [00:02<00:02, 99.1MB/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 217M/434M [00:02<00:02, 102MB/s]  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 228M/434M [00:02<00:02, 103MB/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 238M/434M [00:02<00:01, 106MB/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 248M/434M [00:02<00:01, 101MB/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 258M/434M [00:02<00:01, 95.4MB/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 269M/434M [00:02<00:01, 100MB/s]  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 279M/434M [00:02<00:01, 100MB/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 289M/434M [00:02<00:01, 103MB/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 299M/434M [00:03<00:01, 97.6MB/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 309M/434M [00:03<00:01, 99.9MB/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 320M/434M [00:03<00:01, 106MB/s]  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 331M/434M [00:03<00:01, 102MB/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 341M/434M [00:03<00:00, 105MB/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 352M/434M [00:03<00:00, 92.7MB/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 363M/434M [00:03<00:00, 100MB/s]  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 374M/434M [00:03<00:00, 104MB/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 384M/434M [00:03<00:00, 95.9MB/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 395M/434M [00:04<00:00, 102MB/s]  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 405M/434M [00:04<00:00, 102MB/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 415M/434M [00:04<00:00, 96.8MB/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 425M/434M [00:04<00:00, 88.6MB/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 434M/434M [00:04<00:00, 100MB/s] 
Traceback (most recent call last):
  File "run_gen.py", line 237, in <module>
    run(args)
  File "run_gen.py", line 101, in run
    model = UNIMOLMHeadModel.from_pretrained(args.model_name_or_path)
  File "/data/lzp/anaconda3/envs/race/lib/python3.7/site-packages/paddlenlp/transformers/model_utils.py", line 477, in from_pretrained
    return cls.from_pretrained_v2(pretrained_model_name_or_path, from_hf_hub=from_hf_hub, *args, **kwargs)
  File "/data/lzp/anaconda3/envs/race/lib/python3.7/site-packages/paddlenlp/transformers/model_utils.py", line 1330, in from_pretrained_v2
    model_state_dict = paddle.load(model_weight_file, return_numpy=load_state_as_np)
  File "/data/lzp/anaconda3/envs/race/lib/python3.7/site-packages/paddle/framework/io.py", line 1055, in load
    load_result[key], config.return_numpy
  File "/data/lzp/anaconda3/envs/race/lib/python3.7/site-packages/paddle/framework/io.py", line 455, in _ndarray_to_tensor
    return paddle.to_tensor(obj)
  File "/data/lzp/anaconda3/envs/race/lib/python3.7/site-packages/paddle/tensor/creation.py", line 546, in to_tensor
    return _to_tensor_non_static(data, dtype, place, stop_gradient)
  File "/data/lzp/anaconda3/envs/race/lib/python3.7/site-packages/paddle/tensor/creation.py", line 411, in _to_tensor_non_static
    stop_gradient=stop_gradient,
OSError: (External) CUDA error(222), the provided PTX was compiled with an unsupported toolchain.. 
  [Hint: Please search for the error code(222) on website (https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g3f51e3575c2178246db0a94a430e0038) to get Nvidia's official solution and advice about CUDA Error.] (at /paddle/paddle/fluid/platform/device/gpu/gpu_info.cc:142)

